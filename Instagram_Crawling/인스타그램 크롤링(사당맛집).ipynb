{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 함수 정의하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인스타그램 검색 결과 URL을 만들어서 접속하기 (insta_searching 함수 만들기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#함수 작성\n",
    "def insta_searching(word):  #word라는 매개변수를 받는 insta_searching 이라는 함수 생성\n",
    "    url = 'https://www.instagram.com/explore/tags/' + word\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 게시글 열기 (selet_first 함수 만들기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#열린 크롬으로 개발자 도구 활용하여 첫번째 게시물 태그 확인 (<div class=\"_9AhH0\"></div>)\n",
    "#첫번째 게시물 찾아 클릭 함수 만들기\n",
    "\n",
    "import time\n",
    "\n",
    "def select_first(driver):\n",
    "    first = driver.find_element_by_css_selector('div._9AhH0') #find_element_by_css_selector 함수를 사용해 요소 찾기\n",
    "    first.click()\n",
    "    time.sleep(3) #로딩을 위해 3초 대기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "게시글 정보 가져오기 (get_content 함수 만들기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#본문 내용, 작성 일시, 위치 정보 및 해시태그(#) 추출\n",
    "\n",
    "import re\n",
    "\n",
    "def get_content(driver):\n",
    "    # 1. 현재 페이지의 HTML 정보 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    # 2. 본문 내용 가져오기\n",
    "    try:                                         #여러 태그중 첫번째([0]) 태그를 선택  \n",
    "        content = soup.select('div.C4VMK > span')[0].text #첫 게시글 본문 내용이 <div class=\"C4VMK\"> 임을 알 수 있다.\n",
    "                                #태그명이 div, class명이 C4VMK인 태그 아래에 있는 span 태그를 모두 선택.\n",
    "    except:\n",
    "        content = ' ' \n",
    "        \n",
    "    # 3. 본문 내용에서 해시태그 가져오기(정규표현식 활용)\n",
    "    tags = re.findall(r'#[^\\s#,\\\\]+', content) \n",
    "        # content 변수의 본문 내용 중 #으로 시작하며, #뒤에 연속된 문자(공백이나 #, \\ 기호가 아닌 경우)를 모두 찾아 tags 변수에 저장\n",
    "    \n",
    "    # 4. 작성 일자 가져오기\n",
    "    try:\n",
    "        date = soup.select('time._1o9PC.Nzb55')[0]['datetime'][:10] #앞에서부터 10자리 글자\n",
    "    except:\n",
    "        date = ''\n",
    "\n",
    "    # 5. 좋아요 수 가져오기\n",
    "    try:\n",
    "        like = soup.select('div.Nm9Fw > button')[0].text[4:-1] \n",
    "    except:\n",
    "        like = 0\n",
    "        \n",
    "    # 6. 위치 정보 가져오기\n",
    "    try:\n",
    "        place = soup.select('div.JF9hh')[0].text\n",
    "    except:\n",
    "        place = ''\n",
    "    \n",
    "    # 7. 수집한 정보 저장하기\n",
    "    data = [content, date, like, place, tags]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 게시글 열기 (move_next 함수 만들기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_next(driver):\n",
    "    right = driver.find_element_by_css_selector('a._65Bje.coreSpriteRightPaginationArrow') \n",
    "    right.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☆ 여러 게시글 정보 수집하기 (만든 함수들로 코딩하기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['#당산오돌한번 꽂힌 이후로 주기적으로 가게 되는 듯 ‼️친구가 알아 온 사당맛집 넘 안땡겨서 🤣😂😅그냥 내가 좋아하는 익숙한 당산오돌로 (이기적😚🥰)친구도 다행히 좋아해땨.. 😍소금에 콕 찍어서 먹는 육즙 가득 꼬들살 🐷🍗💞허버허버 먹다가 입천장 까졌따뤼 흑흑,,⠀#사당맛집 #사당역맛집 #사당고기집 #사당맛집추천', '2020-05-26', '1,162', '사당역', ['#당산오돌한번', '#사당맛집', '#사당역맛집', '#사당고기집', '#사당맛집추천']], ['#얼쑤 #신토불이 족발에 막걸리 한잔!맛, 서비스, 위생, 청결, 규모 그 어디도 빠지지 않는 사당역 랜드마크! #사당맛집 #사당역맛집 #사당역모임장소 #사당회식장소 #방배동맛집 #방배맛집 #사당고기집', '2020-06-16', '1,311', '수향가 사당점', ['#얼쑤', '#신토불이', '#사당맛집', '#사당역맛집', '#사당역모임장소', '#사당회식장소', '#방배동맛집', '#방배맛집', '#사당고기집']]]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "# 1. 크롬으로 인스타그램 - '사당맛집' 검색\n",
    "driver = webdriver.Chrome(\"C:\\\\Users\\\\KIM EUNKI\\\\anaconda3\\\\chromedriver.exe\")\n",
    "word = '사당맛집'\n",
    "url = insta_searching(word)\n",
    "driver.get(url) \n",
    "time.sleep(4)\n",
    "\n",
    "# 2. 로그인 하기\n",
    "login_section = '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[3]/div/span/a[1]/button'\n",
    "driver.find_element_by_xpath(login_section).click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "elem_login = driver.find_element_by_name(\"username\")\n",
    "elem_login.clear()\n",
    "elem_login.send_keys('ekey_11_11')\n",
    "\n",
    "elem_login = driver.find_element_by_name('password')\n",
    "elem_login.clear()\n",
    "elem_login.send_keys('test12345')\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "xpath = \"\"\"//*[@id=\"react-root\"]/section/main/div/article/div/div[1]/div/form/div[4]/button\"\"\"\n",
    "driver.find_element_by_xpath(xpath).click()\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "xpath1 = \"\"\"//*[@id=\"react-root\"]/section/main/div/div/div/div/button\"\"\"\n",
    "driver.find_element_by_xpath(xpath1).click()\n",
    "time.sleep(4)\n",
    "\n",
    "# 3. 검색페이지 접속하기\n",
    "driver.get(url)\n",
    "time.sleep(4)\n",
    "\n",
    "# 4. 첫번째 게시글 열기\n",
    "select_first(driver)\n",
    "\n",
    "# 5. 비어있는 변수(results) 만들기\n",
    "results = []\n",
    "\n",
    "# 여러 게시물 크롤링하기\n",
    "target = 1000 #크롤링할 게시물 수\n",
    "for i in range(target):\n",
    "    data = get_content(driver) #게시물 정보 가져오기\n",
    "    results.append(data)\n",
    "    move_next(driver)\n",
    "    \n",
    "print(results[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1000개 추출해서 2개만 표시해보았음.\n",
    "#추출한 데이터를 데이터프레임 results_df 변수에 저장.\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['content', 'data', 'like', 'place', 'tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ec96fb0cb981>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "results_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [#당산오돌한번, #사당맛집, #사당역마...\n",
       "1      [#얼쑤, #신토불이, #사당맛집, #사당역맛집, #사당역모임장소, #사당회식장소,...\n",
       "2      [#사당맛집, #사당역맛집, #사당역모임...\n",
       "3      [#사당맛집, #사당족발, #사당역맛집, ...\n",
       "4      [#떡, #이수떡집, #정애맛담, #민속떡지...\n",
       "                             ...                        \n",
       "995    [#이수맛집, #사당맛집, #이수역맛집, #ᄋ...\n",
       "996                                            [#카페좋아진다]\n",
       "997    [#이태리레스토랑, #사당, #사당맛집, #사당점심, #사당소개팅, #사당술집, #...\n",
       "998    [#100족발.., #사당맛집, #사당역맛집, #사당술집, #사당역술집, #사당역족...\n",
       "999    [#아이스아메리카노, #KIMBO, #espresso, #방배역, #방배동, #서래...\n",
       "Name: tags, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수집한 데이터 엑셀파일로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['content', 'data', 'like', 'place', 'tags']\n",
    "results_df.to_excel(\"C:\\\\Users\\\\KIM EUNKI\\\\Google 드라이브\\\\GitHub\\\\Practice\\\\Insta_Sadang.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
